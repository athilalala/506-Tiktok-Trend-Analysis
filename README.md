# 506 – TikTok Trend Analysis  
## TikTok Virality Prediction Using Multimodal Data


## Project Description
This project investigates the factors influencing TikTok video virality using a multimodal data science approach. The study integrates Natural Language Processing (NLP) to analyze captions, titles, and hashtags, Computer Vision techniques to examine video content, and early engagement signals such as initial views, likes, and comments.  

The objective is to identify key drivers of virality and evaluate whether combining textual, visual, and engagement-based features improves the accuracy of predicting video performance.


## Project Goals

- Successfully predict whether a TikTok video will perform above average using caption text, hashtags, visual content, and early engagement metrics within the first **24–72 hours** after posting.  
- Evaluate the contribution of computer vision–derived visual features alongside textual and engagement data to improve virality prediction.



## Data Collection Plan

### Potential Data Sources
- Public TikTok datasets from platforms such as Kaggle and HuggingFace containing captions, hashtags, engagement metrics, and video metadata.

### Data Collection Method
- Primary data will be obtained from publicly available datasets.  
- If required, additional publicly accessible TikTok content will be collected using ethical scraping tools to obtain captions, engagement metrics, and video links.



## Proposed Timeline

- Data Collection (1 week): Identification and acquisition of multimodal TikTok datasets (text, engagement metrics, video content).  
- Data Preprocessing (1 week): Text cleaning, handling missing values, normalization of engagement metrics, and video frame preparation.  
- Feature Engineering (3 weeks): Extraction of NLP features, computer vision features from video frames, and early engagement indicators.  
- Exploratory Analysis & Visualization (1 week): Descriptive analysis, trend visualization, and feature relationship assessment.  
- Model Development & Evaluation (2 weeks): Multimodal model training, performance evaluation, and comparative analysis.






